#!/usr/bin/env python3
import sys
import os
import glob
from collections import defaultdict
from argparse import ArgumentParser, SUPPRESS
from math import floor, ceil
import cv2
import numpy as np
import logging as log
from openvino.inference_engine import IECore

#path = "C:/Users/Ismail/Documents/Projects/Detect Cars/"

def build_argparser():
    parser = ArgumentParser(add_help=False)
    args = parser.add_argument_group("Options")
    args.add_argument('-h', '--help', action='help', default=SUPPRESS, help='Show this help message and exit.')
    args.add_argument('-m', '--model', help='Path to the model .xml file', required=True, type=str)
    args.add_argument('-i', '--input', help='Path to images directory', required=False, type=str)
    args.add_argument('-v', '--video', help='Path to video file', required=False, type=str)
    args.add_argument('-c', '--confidence', help='Minimum score to accept a detection', required=False, type=float, default=0.4)
    args.add_argument('-s', '--save', help='Save results to image files', required=False, action='store_true')
    return parser

def main():
    log.basicConfig(format="[ %(levelname)s ] %(message)s", level=log.INFO, stream=sys.stdout)
    args = build_argparser().parse_args()
    log.info("Loading Inference Engine")
    ie = IECore()
    # --------------------------- 1. Read IR Generated by ModelOptimizer (.xml and .bin files) ------------
    model_xml = args.model
    model_bin = model_xml[:-3] + 'bin'
    log.info("Loading network files:\n\t{}\n".format(model_xml))
    net = ie.read_network(model=model_xml, weights=model_bin)
    # -----------------------------------------------------------------------------------------------------

    # ------------- 2. Load Plugin for inference engine and extensions library if specified --------------
    log.info("Device info:")
    device = 'CPU'
    versions = ie.get_versions(device)
    print("{}{}".format(" " * 8, device))
    print("{}MKLDNNPlugin version ......... {}.{}".format(" " * 8, versions[device].major,
                                                          versions[device].minor))
    print("{}Build ........... {}".format(" " * 8, versions[device].build_number))

    supported_layers = ie.query_network(net, "CPU")
    not_supported_layers = [l for l in net.layers.keys() if l not in supported_layers]
    if len(not_supported_layers) != 0:
        log.error("Following layers are not supported by the plugin for specified device {}:\n {}".
                  format(device, ', '.join(not_supported_layers)))
        log.error("Please try to specify cpu extensions library path in sample's command line parameters using -l "
                  "or --cpu_extension command line argument")
        sys.exit(1)
    # -----------------------------------------------------------------------------------------------------

    infos = [*net.input_info]
    print("inputs number: " + str(len(infos)))
    print("input shape: " + str(net.input_info[infos[0]].input_data.shape))
    print("input key: " + infos[0])
    n, c, h, w = net.input_info[infos[0]].input_data.shape

    log.info("Preparing input blobs")

    out_blob = next(iter(net.outputs))
    input_name = infos[0]
    log.info("Batch size is {}".format(net.batch_size))
    net.input_info[infos[0]].precision = 'U8'

    log.info('Preparing output blobs')

    output_name, output_info = "", net.outputs[next(iter(net.outputs.keys()))]
    for output_key in net.outputs:
        if net.layers[output_key].type == "DetectionOutput":
            output_name, output_info = output_key, net.outputs[output_key]

    if output_name == "":
        log.error("Can't find a DetectionOutput layer in the topology")

    output_dims = output_info.shape
    if len(output_dims) != 4:
        log.error("Incorrect output dimensions for SSD model")
    max_proposal_count, object_size = output_dims[2], output_dims[3]

    if object_size != 7:
        log.error("Output item should have 7 as a last dimension")

    output_info.precision = "FP32"

    log.info("Loading model to the device")
    exec_net = ie.load_network(network=net, device_name=device)
    log.info("Creating infer request and starting inference")

    # -----------------------------------------------------------------------------------------------------

    if args.video is not None and args.input is not None:
        raise RuntimeError('Either use video or images input')
    if args.video is None and args.input is None:
        raise RuntimeError('Need an input: video or images')
    has_video = False
    if args.video is not None:
        has_video = True

    log.info('Processing and ' + ('sav' if args.save else 'show') + 'ing ' + ('video' if has_video else 'images'))
    if args.save:
        if has_video:
            outdir = os.path.dirname(args.video) + os.path.sep + 'results' + os.path.sep
        else:
            outdir = args.input + os.path.sep + 'results' + os.path.sep
        os.makedirs(outdir, exist_ok=True)

    if has_video:
        cap = cv2.VideoCapture(args.video)
        fps = cap.get(cv2.CAP_PROP_FPS)
        video_length = cap.get(cv2.CAP_PROP_FRAME_COUNT)
        ret, image = cap.read()  # first frame just to read size (...)
        size = (image.shape[1], image.shape[0])
        if args.save:
            writer = cv2.VideoWriter(outdir + os.path.basename(args.video) ,cv2.VideoWriter_fourcc(*'mp4v'), fps, size)
    else:
        filenames = glob.glob(args.input + '/*.jpg') + glob.glob(args.input + '/*.png')

    network_ratio = w / h
    count = -1
    while True:
        count += 1
        if has_video:
            ret, image = cap.read()
            name = f'frame{count}'
            if count % 10 == 0:
                print('Progress: %.2f%%' % (100.0 * count/video_length), end='\r', flush=True)
            if not ret:
                break
        else:
            if count == len(filenames):
                break
            name = filenames[count]
            image = cv2.imread(name)

        output = []
        ih, iw = image.shape[:-1]
        input_ratio = iw / ih
        if input_ratio < network_ratio:
            new_h = int(floor(w / input_ratio))
            new_w = w
            scale_ratio = iw / w
            off_h = int(floor((new_h - h) / 2))
            off_w = 0
        else:
            new_h = h
            new_w = int(floor(h * input_ratio))
            scale_ratio = ih / h
            off_h = 0
            off_w = int(floor((new_w - w) / 2))

        crop = cv2.resize(image, (new_w, new_h))
        crop = crop[off_h:off_h + h, off_w:off_w + w, :]
        images_hw = crop.shape[:-1]

        if False:
            log.info("File added: ")
            log.info("        {} - size {}x{}".format(name, *crop.shape[:-1]))
            cv2.imshow('img', image)
            cv2.imshow('crop', crop)
            cv2.waitKey(0)

        data = {input_name: crop.transpose((2, 0, 1))} # Change data layout from HWC to CHW
        res = exec_net.infer(inputs=data)
        res = res[out_blob][0][0]
        for number, proposal in enumerate(res):
            if proposal[2] > 0:
                ih, iw = images_hw
                label = np.int(proposal[1])
                confidence = proposal[2]
                xmin = np.int(scale_ratio * (off_w + iw * proposal[3]))
                ymin = np.int(scale_ratio * (off_h + ih * proposal[4]))
                xmax = np.int(scale_ratio * (off_w + iw * proposal[5]))
                ymax = np.int(scale_ratio * (off_h + ih * proposal[6]))
                if confidence > args.confidence:
                    output.append((xmin, ymin, xmax, ymax, confidence, label))
                    """if not args.save:
                        print("[{},{}] element, prob = {:.6}    ({},{})-({},{})" \
                              .format(number, label, confidence, xmin, ymin, xmax, ymax))"""

        img = image
        for box in output:
            if box[5] == 1:
                cl = (255, 0, 0)
            else:
                cl = (0, 0, 255)
            cv2.rectangle(img, (box[0], box[1]), (box[2], box[3]), cl, 2)
            print(box)

        if args.save:
            if has_video:
                writer.write(img)
            else:
                base = os.path.basename(name)
                log.info(f'Write to {outdir + base}')
                cv2.imwrite(outdir + base, img)
        else:
            cv2.imshow('result', img)
            cv2.waitKey(0)

    # -----------------------------------------------------------------------------------------------------
    if has_video:
        cap.release()
        if args.save:
            writer.release()
    log.info("Execution successful\n")

if __name__ == '__main__':
    sys.exit(main() or 0)