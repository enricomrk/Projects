<<<<<<< HEAD
#!/usr/bin/env python3
import sys
import os
import glob
from collections import defaultdict
from argparse import ArgumentParser, SUPPRESS
from math import floor, ceil
import cv2
import numpy as np
import logging as log
from openvino.inference_engine import IECore

<<<<<<<< HEAD:car_detection/object_detection_sample_ssd_last.py
path = "C:/Users/Ismail/Documents/Projects/Detect Cars/"
video_input = path + "volta_test_night_0.mp4"

# Opens the Video file
cap= cv2.VideoCapture(video_input)
i=0
========
#path = "C:/Users/Ismail/Documents/Projects/Detect Cars/"
>>>>>>>> ebcc4535b43295fb39a14efe749bbb7c403638be:car_detection/object_detection_sample_ssd.py

def build_argparser():
    parser = ArgumentParser(add_help=False)
    args = parser.add_argument_group("Options")
    args.add_argument('-h', '--help', action='help', default=SUPPRESS, help='Show this help message and exit.')
<<<<<<<< HEAD:car_detection/object_detection_sample_ssd_last.py
    args.add_argument('-m', '--model', help='xml_model_path', required=True, type=str)
    args.add_argument('-i', '--input', help='images_path', required=True, type=str, nargs='+')
    args.add_argument('-c', '--confidence', help='Minimum score to accept a detection', required=False, type=float,
                      default=0.4)
========
    args.add_argument('-m', '--model', help='Path to the model .xml file', required=True, type=str)
    args.add_argument('-i', '--input', help='Path to images directory', required=False, type=str)
    args.add_argument('-v', '--video', help='Path to video file', required=False, type=str)
    args.add_argument('-c', '--confidence', help='Minimum score to accept a detection', required=False, type=float, default=0.4)
>>>>>>>> ebcc4535b43295fb39a14efe749bbb7c403638be:car_detection/object_detection_sample_ssd.py
    args.add_argument('-s', '--save', help='Save results to image files', required=False, action='store_true')
    return parser

def main():
    log.basicConfig(format="[ %(levelname)s ] %(message)s", level=log.INFO, stream=sys.stdout)
    args = build_argparser().parse_args()
    log.info("Loading Inference Engine")
    ie = IECore()
    # --------------------------- 1. Read IR Generated by ModelOptimizer (.xml and .bin files) ------------
    model_xml = args.model
<<<<<<<< HEAD:car_detection/object_detection_sample_ssd_last.py
    # model_xml = path + "vehicle_detection/vehicle-detection-adas-0002.xml"
========
>>>>>>>> ebcc4535b43295fb39a14efe749bbb7c403638be:car_detection/object_detection_sample_ssd.py
    model_bin = model_xml[:-3] + 'bin'
    log.info("Loading network files:\n\t{}\n".format(model_xml))
    net = ie.read_network(model=model_xml, weights=model_bin)
    # -----------------------------------------------------------------------------------------------------

    # ------------- 2. Load Plugin for inference engine and extensions library if specified --------------
    log.info("Device info:")
    device = 'CPU'
    versions = ie.get_versions(device)
    print("{}{}".format(" " * 8, device))
    print("{}MKLDNNPlugin version ......... {}.{}".format(" " * 8, versions[device].major,
                                                          versions[device].minor))
    print("{}Build ........... {}".format(" " * 8, versions[device].build_number))

    supported_layers = ie.query_network(net, "CPU")
    not_supported_layers = [l for l in net.layers.keys() if l not in supported_layers]
    if len(not_supported_layers) != 0:
        log.error("Following layers are not supported by the plugin for specified device {}:\n {}".
                  format(device, ', '.join(not_supported_layers)))
        log.error("Please try to specify cpu extensions library path in sample's command line parameters using -l "
                  "or --cpu_extension command line argument")
        sys.exit(1)
    # -----------------------------------------------------------------------------------------------------

    infos = [*net.input_info]
    print("inputs number: " + str(len(infos)))
    print("input shape: " + str(net.input_info[infos[0]].input_data.shape))
    print("input key: " + infos[0])
    n, c, h, w = net.input_info[infos[0]].input_data.shape
<<<<<<<< HEAD:car_detection/object_detection_sample_ssd_last.py

    show = False
    images = []
    images_hw = []
    i=0

    while (cap.isOpened()) and i <10:
        ret, frame = cap.read()
        if ret == False:
            break
        image = frame
        ih, iw = image.shape[:-1]
        off = (ih - h)//2
        i_aspect_ratio = ih / iw
        new_h = int(w * i_aspect_ratio)
        image = cv2.resize(image, (new_h, w))
        mid = ih//2
        crop = image[mid-off:off+mid, :, :]
        images_hw.append(crop.shape[:-1])
        log.info("File added: ")
        log.info("        {} - size {}x{}".format(image, *crop.shape[:-1]))
        if show:
            cv2.imshow('img', image)
            cv2.imshow('crop', crop)
            cv2.waitKey(0)

        crop = crop.transpose((2, 0, 1))  # Change data layout from HWC to CHW
        images.append(crop)
        i += 1

    cap.release()
    cv2.destroyAllWindows()

    # -----------------------------------------------------------------------------------------------------
========
>>>>>>>> ebcc4535b43295fb39a14efe749bbb7c403638be:car_detection/object_detection_sample_ssd.py

    log.info("Preparing input blobs")

    out_blob = next(iter(net.outputs))
    input_name = infos[0]
    log.info("Batch size is {}".format(net.batch_size))
    net.input_info[infos[0]].precision = 'U8'

    log.info('Preparing output blobs')

    output_name, output_info = "", net.outputs[next(iter(net.outputs.keys()))]
    for output_key in net.outputs:
        if net.layers[output_key].type == "DetectionOutput":
            output_name, output_info = output_key, net.outputs[output_key]

    if output_name == "":
        log.error("Can't find a DetectionOutput layer in the topology")

    output_dims = output_info.shape
    if len(output_dims) != 4:
        log.error("Incorrect output dimensions for SSD model")
    max_proposal_count, object_size = output_dims[2], output_dims[3]

    if object_size != 7:
        log.error("Output item should have 7 as a last dimension")

    output_info.precision = "FP32"

    log.info("Loading model to the device")
    exec_net = ie.load_network(network=net, device_name=device)
    log.info("Creating infer request and starting inference")

    # -----------------------------------------------------------------------------------------------------
<<<<<<<< HEAD:car_detection/object_detection_sample_ssd_last.py
    # --------------------------- Read and postprocess output ---------------------------------------------
    log.info("Processing output blobs")
    output = defaultdict(list)
    for i in range(len(images)):
        data = {input_name: images[i]}
        print(data)
        res = exec_net.infer(inputs=data)
        res = res[out_blob][0][0]
        for number, proposal in enumerate(res):
            if proposal[2] > 0:
                ih, iw = images_hw[i]
                label = np.int(proposal[1])
                confidence = proposal[2]
                xmin = np.int(iw * proposal[3])
                ymin = np.int(ih * proposal[4])
                xmax = np.int(iw * proposal[5])
                ymax = np.int(ih * proposal[6])
                if confidence > args.confidence:
                    print("[{},{}] element, prob = {:.6}    ({},{})-({},{}) batch id : {}" \
                          .format(number, label, confidence, xmin, ymin, xmax, ymax, i))
                    output[i].append((xmin, ymin, xmax, ymax, confidence))
========

    if args.video is not None and args.input is not None:
        raise RuntimeError('Either use video or images input')
    if args.video is None and args.input is None:
        raise RuntimeError('Need an input: video or images')
    has_video = False
    if args.video is not None:
        has_video = True
>>>>>>>> ebcc4535b43295fb39a14efe749bbb7c403638be:car_detection/object_detection_sample_ssd.py

    log.info('Processing and ' + ('sav' if args.save else 'show') + 'ing ' + ('video' if has_video else 'images'))
    if args.save:
<<<<<<<< HEAD:car_detection/object_detection_sample_ssd_last.py
        outdir = args.input[0] + '/' + 'results' + '/'
        os.makedirs(outdir, exist_ok=True)

    for i in range(len(images)):
        img = images[i]
        img = img.transpose((1, 2, 0))
        for box in output[i]:
            cv2.rectangle(img, (box[0], box[1]), (box[2], box[3]), (255, 0, 0), 2)
        if args.save:
            base = os.path.basename(f"{i}.jpg")
            log.info(f'Write to {outdir + base}')
            cv2.imwrite(outdir + base, img)
        else:
            cv2.imshow('result', img)
            cv2.waitKey(0)
    # -----------------------------------------------------------------------------------------------------
========
        if has_video:
            outdir = os.path.dirname(args.video) + os.path.sep + 'results' + os.path.sep
        else:
            outdir = args.input + os.path.sep + 'results' + os.path.sep
        os.makedirs(outdir, exist_ok=True)

    if has_video:
        cap = cv2.VideoCapture(args.video)
        fps = cap.get(cv2.CAP_PROP_FPS)
        video_length = cap.get(cv2.CAP_PROP_FRAME_COUNT)
        ret, image = cap.read()  # first frame just to read size (...)
        size = (image.shape[1], image.shape[0])
        if args.save:
            writer = cv2.VideoWriter(outdir + os.path.basename(args.video) ,cv2.VideoWriter_fourcc(*'mp4v'), fps, size)
    else:
        filenames = glob.glob(args.input + '/*.jpg') + glob.glob(args.input + '/*.png')

    network_ratio = w / h
    count = -1
    while True:
        count += 1
        if has_video:
            ret, image = cap.read()
            name = f'frame{count}'
            if count % 10 == 0:
                print('Progress: %.2f%%' % (100.0 * count/video_length), end='\r', flush=True)
            if not ret:
                break
        else:
            if count == len(filenames):
                break
            name = filenames[count]
            image = cv2.imread(name)

        output = []
        ih, iw = image.shape[:-1]
        input_ratio = iw / ih
        if input_ratio < network_ratio:
            new_h = int(floor(w / input_ratio))
            new_w = w
            scale_ratio = iw / w
            off_h = int(floor((new_h - h) / 2))
            off_w = 0
        else:
            new_h = h
            new_w = int(floor(h * input_ratio))
            scale_ratio = ih / h
            off_h = 0
            off_w = int(floor((new_w - w) / 2))

        crop = cv2.resize(image, (new_w, new_h))
        crop = crop[off_h:off_h + h, off_w:off_w + w, :]
        images_hw = crop.shape[:-1]

        if False:
            log.info("File added: ")
            log.info("        {} - size {}x{}".format(name, *crop.shape[:-1]))
            cv2.imshow('img', image)
            cv2.imshow('crop', crop)
            cv2.waitKey(0)

        data = {input_name: crop.transpose((2, 0, 1))} # Change data layout from HWC to CHW
        res = exec_net.infer(inputs=data)
        res = res[out_blob][0][0]
        for number, proposal in enumerate(res):
            if proposal[2] > 0:
                ih, iw = images_hw
                label = np.int(proposal[1])
                confidence = proposal[2]
                xmin = np.int(scale_ratio * (off_w + iw * proposal[3]))
                ymin = np.int(scale_ratio * (off_h + ih * proposal[4]))
                xmax = np.int(scale_ratio * (off_w + iw * proposal[5]))
                ymax = np.int(scale_ratio * (off_h + ih * proposal[6]))
                if confidence > args.confidence:
                    output.append((xmin, ymin, xmax, ymax, confidence, label))
                    if not args.save:
                        print("[{},{}] element, prob = {:.6}    ({},{})-({},{})" \
                              .format(number, label, confidence, xmin, ymin, xmax, ymax))

        img = image
        for box in output:
            if box[5] == 1:
                cl = (255, 0, 0)
            else:
                cl = (0, 0, 255)
            cv2.rectangle(img, (box[0], box[1]), (box[2], box[3]), cl, 2)

        if args.save:
            if has_video:
                writer.write(img)
            else:
                base = os.path.basename(name)
                log.info(f'Write to {outdir + base}')
                cv2.imwrite(outdir + base, img)
        else:
            cv2.imshow('result', img)
            cv2.waitKey(0)
>>>>>>>> ebcc4535b43295fb39a14efe749bbb7c403638be:car_detection/object_detection_sample_ssd.py

    # -----------------------------------------------------------------------------------------------------
    if has_video:
        cap.release()
        if args.save:
            writer.release()
    log.info("Execution successful\n")
    """
    img_array = []

    for filename in sorted(glob.glob(outdir + '*.jpg'), key=os.path.getmtime):
        img = cv2.imread(filename)
        height, width, layers = img.shape
        size = (width, height)
        img_array.append(img)

    out = cv2.VideoWriter(path + 'project_3.avi',cv2.VideoWriter_fourcc(*'DIVX'), 28, size)

    for i in range(len(img_array)):
        out.write(img_array[i])

    out.release()"""

if __name__ == '__main__':
=======
import sys
import os
import glob
from collections import defaultdict
from argparse import ArgumentParser, SUPPRESS
import cv2
import numpy as np
import logging as log
from openvino.inference_engine import IECore

path = "C:/Users/Ismail/Documents/Projects/Detect Cars/"
video_input = path + "volta_test_night_0.mp4"

# Opens the Video file
cap= cv2.VideoCapture(video_input)
i=0

def build_argparser():
    parser = ArgumentParser(add_help=False)
    args = parser.add_argument_group("Options")
    args.add_argument('-h', '--help', action='help', default=SUPPRESS, help='Show this help message and exit.')
    args.add_argument('-m', '--model', help='xml_model_path', required=True, type=str)
    args.add_argument('-i', '--input', help='images_path', required=True, type=str, nargs='+')
    args.add_argument('-c', '--confidence', help='Minimum score to accept a detection', required=False, type=float,
                      default=0.4)
    args.add_argument('-s', '--save', help='Save results to image files', required=False, action='store_true')
    return parser

def main():
    log.basicConfig(format="[ %(levelname)s ] %(message)s", level=log.INFO, stream=sys.stdout)
    args = build_argparser().parse_args()
    log.info("Loading Inference Engine")
    ie = IECore()
    # --------------------------- 1. Read IR Generated by ModelOptimizer (.xml and .bin files) ------------
    model_xml = args.model
    # model_xml = path + "vehicle_detection/vehicle-detection-adas-0002.xml"
    model_bin = model_xml[:-3] + 'bin'
    log.info("Loading network files:\n\t{}\n".format(model_xml))
    net = ie.read_network(model=model_xml, weights=model_bin)
    # -----------------------------------------------------------------------------------------------------

    # ------------- 2. Load Plugin for inference engine and extensions library if specified --------------
    log.info("Device info:")
    device = 'CPU'
    versions = ie.get_versions(device)
    print("{}{}".format(" " * 8, device))
    print("{}MKLDNNPlugin version ......... {}.{}".format(" " * 8, versions[device].major,
                                                          versions[device].minor))
    print("{}Build ........... {}".format(" " * 8, versions[device].build_number))

    supported_layers = ie.query_network(net, "CPU")
    not_supported_layers = [l for l in net.layers.keys() if l not in supported_layers]
    if len(not_supported_layers) != 0:
        log.error("Following layers are not supported by the plugin for specified device {}:\n {}".
                  format(device, ', '.join(not_supported_layers)))
        log.error("Please try to specify cpu extensions library path in sample's command line parameters using -l "
                  "or --cpu_extension command line argument")
        sys.exit(1)
    # -----------------------------------------------------------------------------------------------------

    # --------------------------- 3. Read and preprocess input --------------------------------------------

    infos = [*net.input_info]
    print("inputs number: " + str(len(infos)))
    print("input shape: " + str(net.input_info[infos[0]].input_data.shape))
    print("input key: " + infos[0])
    n, c, h, w = net.input_info[infos[0]].input_data.shape

    show = False
    images = []
    images_hw = []
    i=0

    while (cap.isOpened()) and i <10:
        ret, frame = cap.read()
        if ret == False:
            break
        image = frame
        ih, iw = image.shape[:-1]
        off = (ih - h)//2
        i_aspect_ratio = ih / iw
        new_h = int(w * i_aspect_ratio)
        image = cv2.resize(image, (new_h, w))
        mid = ih//2
        crop = image[mid-off:off+mid, :, :]
        images_hw.append(crop.shape[:-1])
        log.info("File added: ")
        log.info("        {} - size {}x{}".format(image, *crop.shape[:-1]))
        if show:
            cv2.imshow('img', image)
            cv2.imshow('crop', crop)
            cv2.waitKey(0)

        crop = crop.transpose((2, 0, 1))  # Change data layout from HWC to CHW
        images.append(crop)
        i += 1

    cap.release()
    cv2.destroyAllWindows()

    # -----------------------------------------------------------------------------------------------------

    # --------------------------- 4. Configure input & output ---------------------------------------------
    # --------------------------- Prepare input blobs -----------------------------------------------------
    log.info("Preparing input blobs")

    out_blob = next(iter(net.outputs))
    input_name = infos[0]
    log.info("Batch size is {}".format(net.batch_size))
    net.input_info[infos[0]].precision = 'U8'

    # --------------------------- Prepare output blobs ----------------------------------------------------
    log.info('Preparing output blobs')

    output_name, output_info = "", net.outputs[next(iter(net.outputs.keys()))]
    for output_key in net.outputs:
        if net.layers[output_key].type == "DetectionOutput":
            output_name, output_info = output_key, net.outputs[output_key]

    if output_name == "":
        log.error("Can't find a DetectionOutput layer in the topology")

    output_dims = output_info.shape
    if len(output_dims) != 4:
        log.error("Incorrect output dimensions for SSD model")
    max_proposal_count, object_size = output_dims[2], output_dims[3]

    if object_size != 7:
        log.error("Output item should have 7 as a last dimension")

    output_info.precision = "FP32"
    # -----------------------------------------------------------------------------------------------------

    # --------------------------- Performing inference ----------------------------------------------------
    log.info("Loading model to the device")
    exec_net = ie.load_network(network=net, device_name=device)
    log.info("Creating infer request and starting inference")

    # -----------------------------------------------------------------------------------------------------
    # --------------------------- Read and postprocess output ---------------------------------------------
    log.info("Processing output blobs")
    output = defaultdict(list)
    for i in range(len(images)):
        data = {input_name: images[i]}
        print(data)
        res = exec_net.infer(inputs=data)
        res = res[out_blob][0][0]
        for number, proposal in enumerate(res):
            if proposal[2] > 0:
                ih, iw = images_hw[i]
                label = np.int(proposal[1])
                confidence = proposal[2]
                xmin = np.int(iw * proposal[3])
                ymin = np.int(ih * proposal[4])
                xmax = np.int(iw * proposal[5])
                ymax = np.int(ih * proposal[6])
                if confidence > args.confidence:
                    print("[{},{}] element, prob = {:.6}    ({},{})-({},{}) batch id : {}" \
                          .format(number, label, confidence, xmin, ymin, xmax, ymax, i))
                    output[i].append((xmin, ymin, xmax, ymax, confidence))

    # -----------------------------------------------------------------------------------------------------
    # --------------------------- Output images -----------------------------------------------------------
    log.info(('Sav' if args.save else 'Show') + 'ing images')
    if args.save:
        outdir = args.input[0] + '/' + 'results' + '/'
        os.makedirs(outdir, exist_ok=True)

    for i in range(len(images)):
        img = images[i]
        img = img.transpose((1, 2, 0))
        for box in output[i]:
            cv2.rectangle(img, (box[0], box[1]), (box[2], box[3]), (255, 0, 0), 2)
        if args.save:
            base = os.path.basename(f"{i}.jpg")
            log.info(f'Write to {outdir + base}')
            cv2.imwrite(outdir + base, img)
        else:
            cv2.imshow('result', img)
            cv2.waitKey(0)
    # -----------------------------------------------------------------------------------------------------

    log.info("Execution successful\n")
    """
    img_array = []

    for filename in sorted(glob.glob(outdir + '*.jpg'), key=os.path.getmtime):
        img = cv2.imread(filename)
        height, width, layers = img.shape
        size = (width, height)
        img_array.append(img)

    out = cv2.VideoWriter(path + 'project_3.avi',cv2.VideoWriter_fourcc(*'DIVX'), 28, size)

    for i in range(len(img_array)):
        out.write(img_array[i])

    out.release()"""

if __name__ == '__main__':
>>>>>>> ebcc4535b43295fb39a14efe749bbb7c403638be
    sys.exit(main() or 0)